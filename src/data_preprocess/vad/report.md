# 算法设计

> 主要使用CNN神经网络对时序信息的处理能力

1. 数据在CNN神经网络中首先进行一维卷积操作，卷积核设置为2，Slide值设置为2。并输出为2个通道（经过测试，3个及3个以上通道收益不佳，故采用两个通道）。
2. 输出的进行批量归一化
3. 输入到relu非线性层中
4. `Flatten`
5. 过一层线性层
6. 最后再过一层非线性 (softmax)

使用交叉熵函数计算Loss值和Adam算法进行优化。

## 数据集生成方法

语音信号会被分为大量的语音片段（240个点），其被作为数据输入到神经网络中，大小为`[N, 1, 1, 240]`。
- reshape为四维矩阵的是为了使用`Conv2d`函数，如果使用`Conv1d`，则应该更改维度。

Label根据语音片段和原始Label标记进行生成，如果语音片段**完全**位于标记的语音信号片段中，则Label为1，否则为0。例如，`[100, 1000]`的区间被标记为语音信号，那么对于音频片段`[0:240]`，其label为0，对于片段`[240:480]`其label为1。

## 运行方法

1. `python model.py`进行模型训练，并在目录下生成`model.pth`
2. `python main.py` 进行算法测试以及绘图，并在predict生成预测文件
3. `python evaluate.py` 进行分数评估

# VAD测试报告

语音识别结果如图所示
---
![图1](./img/data_1.png)
![图2](./img/data_2.png)
![图3](./img/data_3.png)
---

从图中可以看出，CNN网络可以很好的标记出语音信号，并且不受弱噪音的影响。

本实验还使用了evaluate.py对结果进行了进一步评估，结果如下所示。
```sh
# Data 1
f1_score:  0.9105314734888764
accuracy:  0.9571520092954037
recall:  0.8421072929924023
precision:  0.9910584604212055

```

```sh
# Data 2
f1_score:  0.8900238744884038
accuracy:  0.954105457988065
recall:  0.829481881754609
precision:  0.9600993377483443
```

```sh
# Data 3
f1_score:  0.8600238961175375
accuracy:  0.8930134108708756
recall:  0.7712105870440578
precision:  0.9719551282051282
```

均可以达到一个比较好的效果。

# 使用的Python库版本 & Bug排查

本实验使用的库均为官方样例中的库，其中Pytorch版本为`2.3.0`。
其他的库版本可以参见[yml文件](./vad.yml)，但版本不同应该不会造成Exception.

值得注意的是，model使用了MPS进行训练，因此在部分电脑上直接加载模型可能会存在问题。